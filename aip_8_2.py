import os
import cv2
import numpy as np
import tensorflow as tf
from matplotlib import pyplot as plt

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam

# ì´ë¯¸ì§€ ë°›ì•„ì˜¤ê¸° -> ì´ë¯¸ì§€ ì „ì²˜ë¦¬ -> ì „ì²˜ë¦¬ ëœ ì´ë¯¸ì§€ ë³€ìˆ˜ì— ë„£ê¸°(x_train, y_train), (x_test, y_test)
# ì´ë¯¸ì§€ í‰íƒ„í™”( 1ê°œì˜ ë°°ì—´ë¡œ ) -> ëª¨ë¸ ë§Œë“¤ê¸° -> ëª¨ë¸ ì»´íŒŒì¼

# ì´ë¯¸ì§€ íŒŒì¼ ìœ„ì¹˜
train_dir = r'C:\Users\USER\.cache\kagglehub\datasets\volkandl\car-brand-logos\versions\1\Car_Brand_Logos\Train'
test_dir = r'C:\Users\USER\.cache\kagglehub\datasets\volkandl\car-brand-logos\versions\1\Car_Brand_Logos\Test'

# íŒŒì¼ì„ ì°¾ì•„ì˜¤ëŠ” í•¨ìˆ˜
def load_images(folder, class_map):
    images = []
    labels = []
    for brand, index in class_map.items():
        brand_path = os.path.join(folder, brand)
        if os.path.isdir(brand_path):
            for img_file in os.listdir(brand_path):
                img_path = os.path.join(brand_path, img_file)
                try:
                    img = cv2.imread(img_path)
                    if img is None:
                        raise ValueError(f"Invalid image: {img_path}")
                    # img = cv2.resize(img, (224, 224))
                    img = cv2.resize(img, (128, 128))  # ì´ë¯¸ì§€ í¬í‚¤ê°€ ì»¤ì§€ë©´ í•™ìŠµë¥ ë„ ì˜¬ë¼ê° 64ë³´ë‹¨ ë‚³ì•„ì§
                    # img = cv2.resize(img, (64, 64))
                    img = img / 255.0  # ì‚¬ì „ ì •ê·œí™”
                    images.append(img)
                    labels.append(index)
                except Exception as e:
                    print(f"âš ï¸ ì†ìƒëœ íŒŒì¼ ê±´ë„ˆë›°ê¸°: {img_path}")
    return np.array(images), np.array(labels)

class_map = {brand: idx for idx, brand in enumerate(os.listdir(train_dir))}

num_classes = len(class_map)  # í´ë ˆìŠ¤ ê¸¸ì´ í™•ì¸

# ê° í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë³€ìˆ˜ì— ì…ë ¥, ë™ì‹œì— ì •ê·œí™” ìˆ˜í–‰
x_train, y_train = load_images(train_dir, class_map)
x_test, y_test = load_images(test_dir, class_map)

# shape[0] ì´ë¯¸ì§€ì˜ ê°œìˆ˜ / 244, 244ì€ ì„¸ë¡œ, ê°€ë¡œ í”½ì…€ ìˆ˜ / 3ì€ rgb ì»¬ëŸ¬ ìˆ˜  // 64 64ë¡œ ë³€ê²½
x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], x_train.shape[3])
x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3])

sample_num = x_train.shape[1] * x_test.shape[2] * x_test.shape[3]

# ì •ê·œí™”
# x_train = x_train/255.0
# x_test = x_test/255.0

# # ì´ë¯¸ì§€ í‰íƒ„í™” 3D -> 1D
# x_train = x_train.reshape(x_train.shape[0], -1)  # (ìƒ˜í”Œìˆ˜, 224*224*3)
# x_test = x_test.reshape(x_test.shape[0], -1)
x_train = x_train.reshape(-1, sample_num)  # (ìƒ˜í”Œìˆ˜, 224*224*3)
x_test = x_test.reshape(-1, sample_num)

# ì›í•« ì¸ì½”ë”© ê° ë ˆì´ë¸”ì„ 0ì™€ 1ë¡œë§Œ ì´ë£¨ì–´ì§„ ë²¡í„°ë¡œ ë³€í™˜ / ê° í”½ì…€ì„ 0~8ê¹Œì§€ì˜ ê°’ìœ¼ë¡œ ë³€í™˜(í´ë ˆìŠ¤ê°€ 8ê°œì´ê¸° ë•Œë¬¸)
y_train = to_categorical(y_train, num_classes)
y_test = to_categorical(y_test, num_classes)

# y_train = to_categorical(y_train, num_classes)
# y_test = to_categorical(y_test, num_classes)

## ì—¬ê¸°ê¹Œì§€ëŠ” ë¬¸ì œ ì—†ìŒ

# ëª¨ë¸ ë§Œë“¤ê¸°
model = Sequential([
    # Dense(512, input_shape=(224 * 224 * 3,)),  # í™œì„±í™” í•¨ìˆ˜ ë¶„ë¦¬
    Dense(512, input_shape=(sample_num,)),  # í™œì„±í™” í•¨ìˆ˜ ë¶„ë¦¬
    # Dense(512, input_shape=(64 * 64 * 3,)),  # í™œì„±í™” í•¨ìˆ˜ ë¶„ë¦¬
    # tf.keras.layers.Activation('relu'),  # ëª…ì‹œì  í™œì„±í™” ì¸µ
    # BatchNormalization(),
    # Dense(512, input_shape=(64 * 64 * 3,), activation='relu'),  # í™œì„±í™” í•¨ìˆ˜ ë¶„ë¦¬
    BatchNormalization(),
    tf.keras.layers.Activation('relu'),  # ëª…ì‹œì  í™œì„±í™” ì¸µ
    Dropout(0.3),

    Dense(256),
    # Dense(256, input_shape=(128 * 128 * 3,)),
    # tf.keras.layers.Activation('relu'),
    BatchNormalization(),
    tf.keras.layers.Activation('relu'),
    Dropout(0.25),

    Dense(128, activation='relu'),
    Dropout(0.2),

    # Dense(num_classes, activation='sigmoid')  # í…ŒìŠ¤íŠ¸ ì •í™•ë„ê°€ softmaxì— ë¹„í•´ ì¡°ê¸ˆ ë–¨ì–´ì§
    Dense(num_classes, activation='softmax')
])

# gkrtmq tmzpwnffld í•™ìŠµ ìŠ¤ì¼€ì¤„ë§
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.001,
    # decay_steps=1000,
    # decay_steps=len(x_train) // 224 * 5,  # 5 ì—í¬í¬ ë§ˆë‹¤ ê°ì†Œ
    decay_steps=len(x_train) // 128 * 5,  # 5 ì—í¬í¬ ë§ˆë‹¤ ê°ì†Œ
    # decay_steps = len(x_train) // 64 * 5, # 5 ì—í¬í¬ ë§ˆë‹¤ ê°ì†Œ
    decay_rate=0.9)

model.compile(
    # loss = 'mse',
    loss='categorical_crossentropy', # mseë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì•„ì§
    optimizer= Adam(lr_schedule),
    metrics=['accuracy']
)

hist = model.fit(
    x_train, y_train,
    epochs=50,
    batch_size=64,
    validation_split=0.2,
    verbose=2
)

# test_loss, test_acc = model.evaluate(x_test, y_test)
# print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.4f}")
res = model.evaluate(x_test, y_test)
print(f"Accuracy is", res[1]*100)


# plt.plot(hist.history['accuracy'])
# plt.plot(hist.history['val_accuracy'])
# plt.title('Model Accuracy')
# plt.ylabel('Accuracy')
# plt.xlabel('Epoch')
# plt.legend(['Train', 'Validation'], loc = 'Lower right')
# plt.grid()
# plt.show()
#
# plt.plot(history.history['Loss'])
# plt.plot(history.history['val_Loss'])
# plt.title('Model Loss')
# plt.ylabel('Loss')
# plt.xlabel('Epoch')
# plt.legend(['Train', 'Validation'], loc = 'Upper right')
# plt.grid()
# plt.show()